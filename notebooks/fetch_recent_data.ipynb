{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6d4737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d07df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GitHubDataFetcher:\n",
    "    \"\"\"Fetches and filters data files from GitHub repository.\"\"\"\n",
    "    \n",
    "    def __init__(self, repo_owner: str = \"owlmaps\", repo_name: str = \"map-data\", data_path: str = \"data\"):\n",
    "        \"\"\"\n",
    "        Initialize the fetcher.\n",
    "        \n",
    "        Args:\n",
    "            repo_owner: GitHub repository owner\n",
    "            repo_name: GitHub repository name\n",
    "            data_path: Path to data directory in the repository\n",
    "        \"\"\"\n",
    "        self.repo_owner = repo_owner\n",
    "        self.repo_name = repo_name\n",
    "        self.data_path = data_path\n",
    "        self.api_url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{data_path}\"\n",
    "        self.raw_base_url = f\"https://raw.githubusercontent.com/{repo_owner}/{repo_name}/master/{data_path}/\"\n",
    "        self.date_pattern = re.compile(r'^(\\d{8})\\.json$')\n",
    "    \n",
    "    def check_accessibility(self) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the GitHub API is accessible.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if accessible, False otherwise\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"STEP 1: Checking GitHub API accessibility...\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(self.api_url, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                print(f\"GitHub API is accessible (Status: {response.status_code})\")\n",
    "                print(f\"  URL: {self.api_url}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"GitHub API returned status code: {response.status_code}\")\n",
    "                print(f\"  Response: {response.text[:200]}\")\n",
    "                return False\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            print(\"Connection error: Unable to reach GitHub API\")\n",
    "            print(f\"  Error: {str(e)[:200]}\")\n",
    "            return False\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"equest timed out after 10 seconds\")\n",
    "            return False\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def fetch_directory_contents(self) -> Optional[List[Dict]]:\n",
    "        \"\"\"\n",
    "        Fetch directory contents from GitHub API.\n",
    "        \n",
    "        Returns:\n",
    "            List of file information dictionaries, or None if failed\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"STEP 2: Fetching directory contents...\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(self.api_url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            files_data = response.json()\n",
    "            print(\"Successfully fetched directory contents\")\n",
    "            print(f\"  Total items found: {len(files_data)}\")\n",
    "            \n",
    "            return files_data\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to fetch directory: {e}\")\n",
    "            return None\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to parse JSON response: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def filter_and_parse_files(self, files_data: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Filter JSON files with date pattern and parse their dates.\n",
    "        \n",
    "        Args:\n",
    "            files_data: List of file information from GitHub API\n",
    "            \n",
    "        Returns:\n",
    "            List of parsed file information with dates\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"STEP 3: Filtering and parsing JSON files...\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        json_files = []\n",
    "        skipped_files = []\n",
    "        \n",
    "        for item in files_data:\n",
    "            if item.get('type') == 'file':\n",
    "                filename = item.get('name', '')\n",
    "                match = self.date_pattern.match(filename)\n",
    "                \n",
    "                if match:\n",
    "                    date_str = match.group(1)\n",
    "                    try:\n",
    "                        # Parse date to ensure it's valid\n",
    "                        file_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "                        json_files.append({\n",
    "                            'filename': filename,\n",
    "                            'date': file_date,\n",
    "                            'date_str': date_str,\n",
    "                            'download_url': item.get('download_url'),\n",
    "                            'size': item.get('size', 0),\n",
    "                            'sha': item.get('sha', '')\n",
    "                        })\n",
    "                    except ValueError:\n",
    "                        skipped_files.append(filename)\n",
    "        \n",
    "        print(f\"Found {len(json_files)} JSON files with valid date names\")\n",
    "        if skipped_files:\n",
    "            print(f\"Skipped {len(skipped_files)} files with invalid dates:\")\n",
    "            for fname in skipped_files[:5]:\n",
    "                print(f\"    - {fname}\")\n",
    "        \n",
    "        return json_files\n",
    "    \n",
    "    def sort_by_date(self, json_files: List[Dict], descending: bool = True) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Sort files by date.\n",
    "        \n",
    "        Args:\n",
    "            json_files: List of file information with dates\n",
    "            descending: If True, sort newest first; if False, oldest first\n",
    "            \n",
    "        Returns:\n",
    "            Sorted list of files\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"STEP 4: Sorting files by date...\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        sorted_files = sorted(json_files, key=lambda x: x['date'], reverse=descending)\n",
    "        \n",
    "        order = \"newest to oldest\" if descending else \"oldest to newest\"\n",
    "        print(f\"Sorted {len(sorted_files)} files ({order})\")\n",
    "        \n",
    "        return sorted_files\n",
    "    \n",
    "    def get_recent_files(self, sorted_files: List[Dict], n: int = 5) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Get the N most recent files.\n",
    "        \n",
    "        Args:\n",
    "            sorted_files: List of sorted file information\n",
    "            n: Number of recent files to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            List of N most recent files\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"STEP 5: Selecting {n} most recent files...\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        recent_files = sorted_files[:n]\n",
    "        \n",
    "        print(f\"✓ Selected {len(recent_files)} files:\")\n",
    "        print(f\"\\n{'#':<4} {'Date':<12} {'Filename':<20} {'Size (KB)':<12}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for idx, file_info in enumerate(recent_files, 1):\n",
    "            size_kb = file_info['size'] / 1024\n",
    "            print(f\"{idx:<4} {file_info['date'].strftime('%Y-%m-%d'):<12} {file_info['filename']:<20} {size_kb:>10.1f}\")\n",
    "        \n",
    "        return recent_files\n",
    "    \n",
    "    def display_summary(self, all_files: List[Dict]):\n",
    "        \"\"\"Display summary statistics.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"STEP 6: Summary Statistics\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        if not all_files:\n",
    "            print(\"No files to summarize\")\n",
    "            return\n",
    "        \n",
    "        oldest = all_files[-1]\n",
    "        newest = all_files[0]\n",
    "        total_size_mb = sum(f['size'] for f in all_files) / (1024 * 1024)\n",
    "        avg_size_mb = total_size_mb / len(all_files)\n",
    "        \n",
    "        print(f\"Total JSON files: {len(all_files)}\")\n",
    "        print(f\"Date range: {oldest['date'].strftime('%Y-%m-%d')} to {newest['date'].strftime('%Y-%m-%d')}\")\n",
    "        print(f\"Days covered: {(newest['date'] - oldest['date']).days}\")\n",
    "        print(f\"Total size: {total_size_mb:.2f} MB\")\n",
    "        print(f\"Average file size: {avg_size_mb:.2f} MB\")\n",
    "    \n",
    "    def fetch_and_filter(self, num_recent: int = 5) -> Optional[List[Dict]]:\n",
    "        \"\"\"\n",
    "        Main method to fetch and filter recent files.\n",
    "        \n",
    "        Args:\n",
    "            num_recent: Number of most recent files to return\n",
    "            \n",
    "        Returns:\n",
    "            List of most recent files, or None if failed\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"GITHUB DATA FETCHER - owlmaps/map-data\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Target: {self.repo_owner}/{self.repo_name}/{self.data_path}\")\n",
    "        print(f\"Fetching {num_recent} most recent files...\")\n",
    "        \n",
    "        # Step 1: Check accessibility\n",
    "        if not self.check_accessibility():\n",
    "            return None\n",
    "        \n",
    "        # Step 2: Fetch directory contents\n",
    "        files_data = self.fetch_directory_contents()\n",
    "        if files_data is None:\n",
    "            return None\n",
    "        \n",
    "        # Step 3: Filter and parse files\n",
    "        json_files = self.filter_and_parse_files(files_data)\n",
    "        if not json_files:\n",
    "            print(\"\\nNo valid JSON files found!\")\n",
    "            return None\n",
    "        \n",
    "        # Step 4: Sort by date\n",
    "        sorted_files = self.sort_by_date(json_files, descending=True)\n",
    "        \n",
    "        # Step 5: Get recent files\n",
    "        recent_files = self.get_recent_files(sorted_files, num_recent)\n",
    "        \n",
    "        # Step 6: Display summary\n",
    "        self.display_summary(sorted_files)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"FETCH COMPLETE - Files ready for processing\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return recent_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42f4ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(file_info: Dict, save_path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Download a file from GitHub.\n",
    "    \n",
    "    Args:\n",
    "        file_info: File information dictionary with download_url\n",
    "        save_path: Path where to save the file\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(file_info['download_url'], timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(save_path, 'w') as f:\n",
    "            f.write(response.text)\n",
    "        \n",
    "        print(f\"Downloaded: {file_info['filename']} -> {save_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {file_info['filename']}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c23ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    # Initialize fetcher\n",
    "    fetcher = GitHubDataFetcher()\n",
    "    \n",
    "    # Fetch and filter recent files\n",
    "    recent_files = fetcher.fetch_and_filter(num_recent=5)\n",
    "    \n",
    "    if recent_files:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"RECENT FILES STORED IN VARIABLE\")\n",
    "        print(\"=\" * 80)\n",
    "        print(\"\\nYou can now process these files:\")\n",
    "        print(\"Variable: recent_files\")\n",
    "        print(f\"Type: list of {len(recent_files)} dictionaries\")\n",
    "        print(\"\\nEach dictionary contains:\")\n",
    "        print(\"  - filename: str\")\n",
    "        print(\"  - date: datetime object\")\n",
    "        print(\"  - date_str: str (YYYYMMDD)\")\n",
    "        print(\"  - download_url: str\")\n",
    "        print(\"  - size: int (bytes)\")\n",
    "        print(\"  - sha: str (git hash)\")\n",
    "        \n",
    "        # Example: Print download URLs\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"DOWNLOAD URLs for recent files:\")\n",
    "        print(\"=\" * 80)\n",
    "        for file_info in recent_files:\n",
    "            print(f\"{file_info['filename']}: {file_info['download_url']}\")\n",
    "        \n",
    "        return recent_files\n",
    "    else:\n",
    "        print(\"\\nFailed to fetch recent files\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3f644d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GITHUB DATA FETCHER - owlmaps/map-data\n",
      "================================================================================\n",
      "Target: owlmaps/map-data/data\n",
      "Fetching 5 most recent files...\n",
      "\n",
      "================================================================================\n",
      "STEP 1: Checking GitHub API accessibility...\n",
      "================================================================================\n",
      "GitHub API is accessible (Status: 200)\n",
      "  URL: https://api.github.com/repos/owlmaps/map-data/contents/data\n",
      "\n",
      "================================================================================\n",
      "STEP 2: Fetching directory contents...\n",
      "================================================================================\n",
      "Successfully fetched directory contents\n",
      "  Total items found: 1000\n",
      "\n",
      "================================================================================\n",
      "STEP 3: Filtering and parsing JSON files...\n",
      "================================================================================\n",
      "Found 1000 JSON files with valid date names\n",
      "\n",
      "================================================================================\n",
      "STEP 4: Sorting files by date...\n",
      "================================================================================\n",
      "Sorted 1000 files (newest to oldest)\n",
      "\n",
      "================================================================================\n",
      "STEP 5: Selecting 5 most recent files...\n",
      "================================================================================\n",
      "✓ Selected 5 files:\n",
      "\n",
      "#    Date         Filename             Size (KB)   \n",
      "--------------------------------------------------------------------------------\n",
      "1    2025-09-01   20250901.json             132.3\n",
      "2    2025-08-31   20250831.json             126.1\n",
      "3    2025-08-30   20250830.json             132.7\n",
      "4    2025-08-29   20250829.json             126.3\n",
      "5    2025-08-28   20250828.json             129.9\n",
      "\n",
      "================================================================================\n",
      "STEP 6: Summary Statistics\n",
      "================================================================================\n",
      "Total JSON files: 1000\n",
      "Date range: 2022-12-07 to 2025-09-01\n",
      "Days covered: 999\n",
      "Total size: 93.60 MB\n",
      "Average file size: 0.09 MB\n",
      "\n",
      "================================================================================\n",
      "FETCH COMPLETE - Files ready for processing\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RECENT FILES STORED IN VARIABLE\n",
      "================================================================================\n",
      "\n",
      "You can now process these files:\n",
      "Variable: recent_files\n",
      "Type: list of 5 dictionaries\n",
      "\n",
      "Each dictionary contains:\n",
      "  - filename: str\n",
      "  - date: datetime object\n",
      "  - date_str: str (YYYYMMDD)\n",
      "  - download_url: str\n",
      "  - size: int (bytes)\n",
      "  - sha: str (git hash)\n",
      "\n",
      "================================================================================\n",
      "DOWNLOAD URLs for recent files:\n",
      "================================================================================\n",
      "20250901.json: https://raw.githubusercontent.com/owlmaps/map-data/master/data/20250901.json\n",
      "20250831.json: https://raw.githubusercontent.com/owlmaps/map-data/master/data/20250831.json\n",
      "20250830.json: https://raw.githubusercontent.com/owlmaps/map-data/master/data/20250830.json\n",
      "20250829.json: https://raw.githubusercontent.com/owlmaps/map-data/master/data/20250829.json\n",
      "20250828.json: https://raw.githubusercontent.com/owlmaps/map-data/master/data/20250828.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    recent_files = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d565fafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52031913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f68ed39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
